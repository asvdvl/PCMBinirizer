{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.9.13 (main, Aug 25 2022, 23:26:10) \\n[GCC 11.2.0]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#math\n",
    "import numpy as np\n",
    "#capture\n",
    "import cv2\n",
    "import wave\n",
    "#utils\n",
    "from tqdm import tqdm\n",
    "from IPython.display import Image\n",
    "import datetime\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#disable CUDA devices\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.2\n"
     ]
    }
   ],
   "source": [
    "#neural\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.keras import layers\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 17:39:25.658381: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-24 17:39:26.296016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 599 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050, pci bus id: 0000:02:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "system info\n",
    "-"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU|/device:CPU:0 memory limit: 268435456\n",
      "\n",
      "GPU|/device:GPU:0 memory limit: 628693401\n",
      "device: 0, name: NVIDIA GeForce GTX 1050, pci bus id: 0000:02:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 17:39:26.306437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /device:GPU:0 with 599 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050, pci bus id: 0000:02:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "for i in device_lib.list_local_devices():\n",
    "    print(f'{i.device_type}|{i.name} memory limit: {i.memory_limit}')\n",
    "    print(i.physical_device_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "import data\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reshape(frame):\n",
    "    global WIDTH, HEIGHT\n",
    "    newframe = np.zeros(WIDTH*HEIGHT).reshape(HEIGHT, WIDTH)\n",
    "    if frame.shape[0] == HEIGHT and frame.shape[1] == WIDTH:\n",
    "        return frame\n",
    "    elif frame.shape[0] <= HEIGHT and frame.shape[1] <= WIDTH:\n",
    "        newframe[:frame.shape[0],:frame.shape[1]] = frame\n",
    "    elif frame.shape[0] <= HEIGHT:\n",
    "        newframe[:frame.shape[0],:] = frame[:, :WIDTH]\n",
    "    elif frame.shape[1] <= WIDTH:\n",
    "        newframe[:,:frame.shape[1]] = frame[:HEIGHT, :]\n",
    "    else:\n",
    "        newframe = frame[:HEIGHT, :WIDTH]\n",
    "    return newframe\n",
    "\n",
    "def deinterlase(frame):\n",
    "    even_fields=frame[::2,:];\n",
    "    odd_fields=frame[1::2,:];\n",
    "    return even_fields, odd_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "WIDTH = int(720)\n",
    "HEIGHT = int(625-1)\n",
    "\n",
    "def normilizeFrame(frame):\n",
    "    global WIDTH, HEIGHT\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #change dimentions(choose 1 of 2 options)\n",
    "    #frame = cv2.resize(frame, (WIDTH, HEIGHT), interpolation=cv2.INTER_NEAREST)\n",
    "    frame = reshape(frame)\n",
    "    \n",
    "    return deinterlase(frame)\n",
    "    #return frame / 255.0\n",
    "\n",
    "def retrieve():\n",
    "    global WIDTH, HEIGHT\n",
    "    if cap.grab():\n",
    "        ret, frame = cap.retrieve()\n",
    "        if not ret:\n",
    "            print('error reading frame')\n",
    "            return False, normilizeFrame(np.zeros(WIDTH*HEIGHT).reshape(WIDTH, HEIGHT))\n",
    "        return True, normilizeFrame(frame)\n",
    "    else:\n",
    "        return False, normilizeFrame(np.zeros(WIDTH*HEIGHT).reshape(WIDTH, HEIGHT))\n",
    "\n",
    "def shapeCorrector(frame):\n",
    "    return frame[np.newaxis is None,8:302,25:435]\n",
    "    \n",
    "def getNext():\n",
    "    global first, bottomFrame, half\n",
    "    if first == True:\n",
    "        first = False\n",
    "        half = False\n",
    "        ret, (topFrame, bottomFrame) = retrieve()\n",
    "        return ret, shapeCorrector(topFrame)\n",
    "    \n",
    "    if half:\n",
    "        ret, (topFrame, bottomFrame) = retrieve()\n",
    "        half = False\n",
    "        return ret, shapeCorrector(topFrame)\n",
    "    else:\n",
    "        half = True\n",
    "        return True, shapeCorrector(bottomFrame)\n",
    "\n",
    "def openCap(file):\n",
    "    global cap, half, first\n",
    "    first = True\n",
    "    cap = cv2.VideoCapture(file + '.avi')\n",
    "    if (cap.isOpened()== False): \n",
    "      print(\"Error opening video stream or file\")\n",
    "openCap('./dataset/video')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1501\n",
      "882\n"
     ]
    }
   ],
   "source": [
    "frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "print(frameCount)\n",
    "\n",
    "#tech calc\n",
    "\n",
    "#audio in pcm have 44100 samples in second per channel, respectively we have 88200 samples\n",
    "#per frame we have 44100/25(pal) = 1764 samples(for single channel)(and we take half of frame for learning /2)\n",
    "\n",
    "samplesPerFrame = int(44100/cap.get(cv2.CAP_PROP_FPS)/2)\n",
    "print(samplesPerFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"./dataset/\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "!rm -rf ./dataset\n",
    "!mkdir -p dataset\n",
    "!mkdir -p dataset/cache\n",
    "\n",
    "import shutil\n",
    "shutil.copyfile(fileName + '.avi', f'{dir}video.avi')\n",
    "shutil.copyfile(fileName + '.wav', f'{dir}audio.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initQueues():\n",
    "    global bufR0, bufL1, bufR1, bufR2, bufL2\n",
    "    bufR0 = deque()\n",
    "    bufL1 = deque()\n",
    "    bufR1 = deque()\n",
    "    bufL2 = deque()\n",
    "    bufR2 = deque()\n",
    "    \n",
    "    for i in range(1*16):\n",
    "        bufR0.append(0)\n",
    "    \n",
    "    for i in range(2*16):\n",
    "        bufL1.append(0)\n",
    "    \n",
    "    for i in range(3*16):\n",
    "        bufR1.append(0)\n",
    "    \n",
    "    for i in range(4*16):\n",
    "        bufL2.append(0)\n",
    "    \n",
    "    for i in range(5*16):\n",
    "        bufR2.append(0)    \n",
    "        \n",
    "def pairwise(iterable):\n",
    "    a = iter(iterable)\n",
    "    if len(iterable) % 6 != 0:\n",
    "        print(f'input length detected that is not divisible by 6! all data after the {len(iterable)-(len(iterable) % 6)}({len(iterable) % 6} cells) position will be ignored.')\n",
    "    return zip(a, a, a, a, a, a)\n",
    "    \n",
    "def Abreacker(sample):\n",
    "    global bufR0, bufL1, bufR1, bufR2, bufL2\n",
    "    filtered = np.array([], dtype=np.uint16)\n",
    "    line = np.zeros(6, dtype=np.uint16)\n",
    "\n",
    "    for elem in pairwise(sample):\n",
    "        bufR0.append(elem[1])\n",
    "        bufL1.append(elem[2])\n",
    "        bufR1.append(elem[3])\n",
    "        bufL2.append(elem[4])\n",
    "        bufR2.append(elem[5])\n",
    "        \n",
    "        line[0] = elem[0]\n",
    "        line[1] = bufR0.popleft()\n",
    "        line[2] = bufL1.popleft()\n",
    "        line[3] = bufR1.popleft()\n",
    "        line[4] = bufL2.popleft()\n",
    "        line[5] = bufR2.popleft()\n",
    "                \n",
    "        filtered = np.append(filtered, line)\n",
    "    \n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def initQueuesForDebreacker():\n",
    "    global bufL0D, bufR0D, bufL1D, bufR1D, bufL2D\n",
    "    bufL0D = deque()\n",
    "    bufR0D = deque()\n",
    "    bufL1D = deque()\n",
    "    bufR1D = deque()\n",
    "    bufL2D = deque()\n",
    "    \n",
    "    for i in range(5*16):\n",
    "        bufL0D.append(0)\n",
    "        \n",
    "    for i in range(4*16):\n",
    "        bufR0D.append(0)\n",
    "    \n",
    "    for i in range(3*16):\n",
    "        bufL1D.append(0)\n",
    "    \n",
    "    for i in range(2*16):\n",
    "        bufR1D.append(0)\n",
    "    \n",
    "    for i in range(1*16):\n",
    "        bufL2D.append(0)\n",
    "        \n",
    "def Adebreacker(sample):\n",
    "    global bufL0D, bufR0D, bufL1D, bufR1D, bufL2D\n",
    "    filtered = np.array([], dtype=np.uint16)\n",
    "    line = np.zeros(6, dtype=np.uint16)\n",
    "    \n",
    "    for elem in pairwise(sample):\n",
    "        bufL0D.append(elem[0])\n",
    "        bufR0D.append(elem[1])\n",
    "        bufL1D.append(elem[2])\n",
    "        bufR1D.append(elem[3])\n",
    "        bufL2D.append(elem[4])\n",
    "        \n",
    "        line[0] = bufL0D.popleft()\n",
    "        line[1] = bufR0D.popleft()\n",
    "        line[2] = bufL1D.popleft()\n",
    "        line[3] = bufR1D.popleft()\n",
    "        line[4] = bufL2D.popleft()\n",
    "        line[5] = elem[5]\n",
    "                \n",
    "        filtered = np.append(filtered, line)\n",
    "    \n",
    "    return filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 17:39:26.380882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 599 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050, pci bus id: 0000:02:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "mainAudioFile = wave.open(f'{dir}audio.wav', mode='r')\n",
    "\n",
    "def gen():\n",
    "    global mainAudioFile, samplesPerFrame\n",
    "    \n",
    "    #audio\n",
    "    initQueues()\n",
    "    mainAudioFile.rewind()\n",
    "    \n",
    "    if not (mainAudioFile.getparams()[0] == 2 and mainAudioFile.getparams()[2] == 44100):\n",
    "        print('wrong audiofile params')\n",
    "        sys.exit(1)\n",
    "    \n",
    "    \n",
    "    #video\n",
    "    openCap(f'{dir}video')\n",
    "    frames = cap.get(cv2.CAP_PROP_FRAME_COUNT) -1\n",
    "    \n",
    "    \n",
    "    while int(cap.get(cv2.CAP_PROP_POS_FRAMES)) <= frames:\n",
    "        #audio\n",
    "        frame = mainAudioFile.readframes(samplesPerFrame)\n",
    "        \n",
    "        if len(frame) < samplesPerFrame*2:\n",
    "            frame = frame + b'\\x00' * ((samplesPerFrame*4)-len(frame))\n",
    "        \n",
    "        #video\n",
    "        vframe = getNext()[1]\n",
    "        \n",
    "        yield vframe, (Abreacker(tf.io.decode_raw(frame, tf.uint16, little_endian=True).numpy()))\n",
    "\n",
    "        \n",
    "dataset=tf.data.Dataset.from_generator(\n",
    "    gen, \n",
    "    output_signature=(#tf.TensorSpec(shape=(1, int(HEIGHT/2), WIDTH), dtype=tf.uint8, name='image'),\n",
    "                      tf.TensorSpec(shape=(1, 294, 410), dtype=tf.uint8, name='image'),\n",
    "                      tf.TensorSpec(shape=(samplesPerFrame*2,), dtype=tf.uint16, name='audio'),\n",
    "                      #tf.TensorSpec(shape=(1), dtype=tf.int32, name='frameNum')\n",
    "                     )\n",
    ")#.cache('./dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65452"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dataset.take(1))[0][1].numpy().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#create model\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input = keras.Input(shape=(int(HEIGHT/2), WIDTH), name = 'image')\n",
    "input = keras.Input(shape=(294, 410), name = 'image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 294, 168)\n",
      "(None, 294, 6, 8)\n",
      "diff total:10584\n"
     ]
    }
   ],
   "source": [
    "x = tf.keras.layers.Rescaling(1./255, name='normalize')(input)\n",
    "i = 1\n",
    "x = tf.keras.layers.Conv1D(168, 1, activation='sigmoid', name=f'conv1d_{i}')(x)\n",
    "#i +=1\n",
    "#x = tf.keras.layers.Conv1D(360, 1, activation='sigmoid', name=f'conv1d_{i}')(x)\n",
    "\n",
    "print(x.shape)\n",
    "\n",
    "x = tf.keras.layers.Reshape((x.shape[1], x.shape[2], 1))(x)\n",
    "#\n",
    "#i = 1\n",
    "#x = tf.keras.layers.Conv2D(8, (1, 4), strides=(1,2), activation='relu', name=f'conv2d_{i}')(x)\n",
    "i +=1\n",
    "x = tf.keras.layers.Conv2D(8, (1, 2), strides=(1,2), activation='relu', name=f'conv2d_{i}')(x)\n",
    "i +=1\n",
    "x = tf.keras.layers.Conv2D(8, (1, 14), strides=(1,14), activation='relu', name=f'conv2d_{i}')(x)\n",
    "#i +=1\n",
    "#x = tf.keras.layers.Conv2D(3, 32, activation='sigmoid', name=f'conv2d_{i}')(x)\n",
    "#\n",
    "print(x.shape)\n",
    "print(f'diff total:{x.shape[1]*x.shape[2]*x.shape[3]-(samplesPerFrame*4)}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.layers.Flatten(name='Flatten')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = tf.keras.layers.Dense((samplesPerFrame*2), activation='relu', use_bias=False, name='audio')(x)\n",
    "x = tf.keras.layers.Rescaling(65535, name='normalize_touint')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " image (InputLayer)          [(None, 294, 410)]        0         \n",
      "                                                                 \n",
      " normalize (Rescaling)       (None, 294, 410)          0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 294, 168)          69048     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 294, 168, 1)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 294, 84, 8)        24        \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 294, 6, 8)         904       \n",
      "                                                                 \n",
      " Flatten (Flatten)           (None, 14112)             0         \n",
      "                                                                 \n",
      " audio (Dense)               (None, 1764)              24893568  \n",
      "                                                                 \n",
      " normalize_touint (Rescaling  (None, 1764)             0         \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,963,544\n",
      "Trainable params: 24,963,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Model(input, x)\n",
    "model.summary()\n",
    "\n",
    "#tf.keras.utils.plot_model(model, to_file=\"model.png\", show_shapes=True, show_dtype=False, show_layer_names=True, rankdir=\"TB\", expand_nested=True, dpi=96, layer_range=None, show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compile and learn\n",
    "-"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy', 'mean_squared_error', 'MeanAbsolutePercentageError'])\n",
    "loss = 1\n",
    "prew_loss = loss\n",
    "step = 0    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./logs/ ./model/ ./output/\n",
    "!mkdir logs\n",
    "!mkdir model\n",
    "!mkdir output\n",
    "!mkdir output/flac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfile = 'testfiles/pal/FROZTEN_-_Domestic_Technology'\n",
    "def predict():\n",
    "    global step, testfile, vframe, model, cap\n",
    "    initQueuesForDebreacker()\n",
    "    \n",
    "    openCap(testfile)\n",
    "    bar = tqdm(total=25*20*2, ncols=100, position=0, leave=True)\n",
    "    file = wave.open(f'output/{step}.wav', mode='w')\n",
    "    file.setnchannels(2) \n",
    "    file.setsampwidth(2)\n",
    "    file.setframerate(44100)\n",
    "    ret, vframe = getNext()\n",
    "    frst = True\n",
    "    \n",
    "    while ret:\n",
    "        aframe = Adebreacker((model.predict(vframe, verbose=0, batch_size=64)[0]).astype(np.uint16))\n",
    "        if frst:\n",
    "            frst = False\n",
    "            file.writeframes(aframe[480:].tobytes())\n",
    "        else:\n",
    "            file.writeframes(aframe.tobytes())\n",
    "        bar.update(1)\n",
    "        ret, vframe = getNext()\n",
    "        if int(cap.get(cv2.CAP_PROP_POS_FRAMES)) > 25*20:    #limiting on 20 seconds\n",
    "            ret = False\n",
    "    bar.close()\n",
    "    file.close()\n",
    "    !ffmpeg -loglevel error -hide_banner -i output/{step}.wav -y output/flac/{step}.flac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                      | 0/1000 [00:00<?, ?it/s]2022-10-24 17:40:09.038323: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8500\n",
      "100%|███████████████████████████████████████████████████████████| 1000/1000 [00:51<00:00, 19.25it/s]\n"
     ]
    }
   ],
   "source": [
    "predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "try to generate pcm frame(just for understanding)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "a='./testfiles/pal/sin1k'\n",
    "openCap(a)\n",
    "_, img = getNext()\n",
    "cv2.imwrite('a.png', img[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "fAudioFile = wave.open(f'./testfiles/pal/sin1k.wav', mode='r')\n",
    "b=fAudioFile.readframes(882*2)\n",
    "initQueues()\n",
    "c=Abreacker(np.right_shift(tf.io.decode_raw(b, tf.int16, little_endian=True).numpy(), 2))\n",
    "\n",
    "#np.binary_repr(c.min(), width=14)\n",
    "#np.binary_repr(c.max(), width=14)\n",
    "\n",
    "k = iter(c)\n",
    "zp = zip(k, k, k, k, k, k)\n",
    "frm = np.array([], dtype=np.uint8)\n",
    "\n",
    "for line in zp:\n",
    "    ln = np.array([], dtype=np.uint8)\n",
    "    for sampl in line:\n",
    "        ln = np.append(ln, np.repeat([list(np.binary_repr(sampl, width=14))], 5))\n",
    "    frm = np.append(frm, ln)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "fram = frm.reshape(int(frm.shape[0]/420), 420).astype(np.uint8)\n",
    "fram *= 255\n",
    "cv2.imwrite('b.png', fram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   3000/Unknown - 70s 23ms/step - loss: 426210208.0000 - binary_accuracy: 3.6735e-05 - mean_squared_error: 426210208.0000 - mean_absolute_percentage_error: 559384000.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 17:43:01.809085: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 5974456320 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3001/3001 [==============================] - 73s 24ms/step - loss: 426136288.0000 - binary_accuracy: 5.1737e-05 - mean_squared_error: 426136288.0000 - mean_absolute_percentage_error: 2668331776.0000\n",
      "Epoch 2/10\n",
      "3001/3001 [==============================] - ETA: 0s - loss: 408286144.0000 - binary_accuracy: 2.7841e-05 - mean_squared_error: 408286144.0000 - mean_absolute_percentage_error: 3776953600.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 17:44:14.853180: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 5974456320 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3001/3001 [==============================] - 73s 24ms/step - loss: 408286144.0000 - binary_accuracy: 2.7841e-05 - mean_squared_error: 408286144.0000 - mean_absolute_percentage_error: 3776953600.0000\n",
      "Epoch 3/10\n",
      "3001/3001 [==============================] - ETA: 0s - loss: 400670880.0000 - binary_accuracy: 2.6496e-05 - mean_squared_error: 400670880.0000 - mean_absolute_percentage_error: 3946409472.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 17:45:26.869890: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 5974456320 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3001/3001 [==============================] - 72s 24ms/step - loss: 400670880.0000 - binary_accuracy: 2.6496e-05 - mean_squared_error: 400670880.0000 - mean_absolute_percentage_error: 3946409472.0000\n",
      "Epoch 4/10\n",
      "3001/3001 [==============================] - ETA: 0s - loss: 398012832.0000 - binary_accuracy: 2.9137e-05 - mean_squared_error: 398012832.0000 - mean_absolute_percentage_error: 2233491968.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 17:46:38.421017: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 5974456320 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3001/3001 [==============================] - 72s 24ms/step - loss: 398012832.0000 - binary_accuracy: 2.9137e-05 - mean_squared_error: 398012832.0000 - mean_absolute_percentage_error: 2233491968.0000\n",
      "Epoch 5/10\n",
      "3000/3001 [============================>.] - ETA: 0s - loss: 397875808.0000 - binary_accuracy: 1.5570e-05 - mean_squared_error: 397875808.0000 - mean_absolute_percentage_error: 1809937152.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 17:47:50.740982: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 5974456320 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3001/3001 [==============================] - 72s 24ms/step - loss: 397838912.0000 - binary_accuracy: 3.1395e-05 - mean_squared_error: 397838912.0000 - mean_absolute_percentage_error: 5785200128.0000\n",
      "Epoch 6/10\n",
      "3001/3001 [==============================] - 72s 24ms/step - loss: 397825024.0000 - binary_accuracy: 2.4051e-05 - mean_squared_error: 397825024.0000 - mean_absolute_percentage_error: 2651622656.0000\n",
      "Epoch 7/10\n",
      "3001/3001 [==============================] - 72s 24ms/step - loss: 389813760.0000 - binary_accuracy: 2.3816e-05 - mean_squared_error: 389813760.0000 - mean_absolute_percentage_error: 2952917504.0000\n",
      "Epoch 8/10\n",
      "3001/3001 [==============================] - 77s 26ms/step - loss: 388494464.0000 - binary_accuracy: 2.3014e-05 - mean_squared_error: 388494464.0000 - mean_absolute_percentage_error: 3160638720.0000\n",
      "Epoch 9/10\n",
      "3001/3001 [==============================] - 77s 26ms/step - loss: 387248960.0000 - binary_accuracy: 2.2934e-05 - mean_squared_error: 387248960.0000 - mean_absolute_percentage_error: 3173442816.0000\n",
      "Epoch 10/10\n",
      "3001/3001 [==============================] - 77s 26ms/step - loss: 387249888.0000 - binary_accuracy: 2.2934e-05 - mean_squared_error: 387249888.0000 - mean_absolute_percentage_error: 3110733056.0000\n",
      "step: 10 min loss: 387248960.0(387248959.0)\n",
      "Epoch 1/10\n",
      "3001/3001 [==============================] - 77s 26ms/step - loss: 387275328.0000 - binary_accuracy: 2.6035e-05 - mean_squared_error: 387275328.0000 - mean_absolute_percentage_error: 5016403968.0000\n",
      "Epoch 2/10\n",
      "3001/3001 [==============================] - 78s 26ms/step - loss: 387312192.0000 - binary_accuracy: 2.2608e-05 - mean_squared_error: 387312192.0000 - mean_absolute_percentage_error: 2553402112.0000\n",
      "Epoch 3/10\n",
      "3001/3001 [==============================] - 76s 25ms/step - loss: 386144032.0000 - binary_accuracy: 2.2416e-05 - mean_squared_error: 386144032.0000 - mean_absolute_percentage_error: 2912240384.0000\n",
      "Epoch 4/10\n",
      "3001/3001 [==============================] - 77s 26ms/step - loss: 385550112.0000 - binary_accuracy: 2.2388e-05 - mean_squared_error: 385550112.0000 - mean_absolute_percentage_error: 2947466240.0000\n",
      "Epoch 5/10\n",
      "3001/3001 [==============================] - 77s 26ms/step - loss: 385558560.0000 - binary_accuracy: 2.5137e-05 - mean_squared_error: 385558560.0000 - mean_absolute_percentage_error: 2454295296.0000\n",
      "Epoch 6/10\n",
      "3001/3001 [==============================] - 76s 25ms/step - loss: 385604960.0000 - binary_accuracy: 2.6769e-05 - mean_squared_error: 385604960.0000 - mean_absolute_percentage_error: 5546452992.0000\n",
      "Epoch 7/10\n",
      "3001/3001 [==============================] - 76s 25ms/step - loss: 385655968.0000 - binary_accuracy: 2.1220e-05 - mean_squared_error: 385655968.0000 - mean_absolute_percentage_error: 2384865024.0000\n",
      "Epoch 8/10\n",
      "3001/3001 [==============================] - 76s 25ms/step - loss: 381364352.0000 - binary_accuracy: 2.1183e-05 - mean_squared_error: 381364352.0000 - mean_absolute_percentage_error: 2985321728.0000\n",
      "Epoch 9/10\n",
      "3001/3001 [==============================] - 75s 25ms/step - loss: 381374880.0000 - binary_accuracy: 2.1029e-05 - mean_squared_error: 381374880.0000 - mean_absolute_percentage_error: 2627404032.0000\n",
      "Epoch 10/10\n",
      "3001/3001 [==============================] - 75s 25ms/step - loss: 381419136.0000 - binary_accuracy: 2.2172e-05 - mean_squared_error: 381419136.0000 - mean_absolute_percentage_error: 5515897344.0000\n",
      "step: 20 min loss: 381364352.0(-5884608.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 1000/1000 [00:51<00:00, 19.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3001/3001 [==============================] - 76s 25ms/step - loss: 381480864.0000 - binary_accuracy: 2.0703e-05 - mean_squared_error: 381480864.0000 - mean_absolute_percentage_error: 2451333120.0000\n",
      "Epoch 2/10\n",
      "3001/3001 [==============================] - 76s 25ms/step - loss: 379454496.0000 - binary_accuracy: 2.0208e-05 - mean_squared_error: 379454496.0000 - mean_absolute_percentage_error: 2732729088.0000\n",
      "Epoch 3/10\n",
      "3001/3001 [==============================] - 75s 25ms/step - loss: 378318368.0000 - binary_accuracy: 2.4019e-05 - mean_squared_error: 378318368.0000 - mean_absolute_percentage_error: 2553819648.0000\n",
      "Epoch 4/10\n",
      "3001/3001 [==============================] - 76s 25ms/step - loss: 378142560.0000 - binary_accuracy: 2.4645e-05 - mean_squared_error: 378142560.0000 - mean_absolute_percentage_error: 5862842880.0000\n",
      "Epoch 5/10\n",
      "3001/3001 [==============================] - 76s 25ms/step - loss: 377914848.0000 - binary_accuracy: 1.9723e-05 - mean_squared_error: 377914848.0000 - mean_absolute_percentage_error: 2335442944.0000\n",
      "Epoch 6/10\n",
      "3001/3001 [==============================] - 76s 25ms/step - loss: 377270560.0000 - binary_accuracy: 1.9721e-05 - mean_squared_error: 377270560.0000 - mean_absolute_percentage_error: 2183849984.0000\n",
      "Epoch 7/10\n",
      "3001/3001 [==============================] - 76s 25ms/step - loss: 377283808.0000 - binary_accuracy: 1.9696e-05 - mean_squared_error: 377283808.0000 - mean_absolute_percentage_error: 4020977664.0000\n",
      "Epoch 8/10\n",
      "3001/3001 [==============================] - 76s 25ms/step - loss: 377351776.0000 - binary_accuracy: 3.0236e-04 - mean_squared_error: 377351776.0000 - mean_absolute_percentage_error: 1777038720.0000\n",
      "Epoch 9/10\n",
      "3001/3001 [==============================] - 77s 25ms/step - loss: 377356832.0000 - binary_accuracy: 3.0236e-04 - mean_squared_error: 377356832.0000 - mean_absolute_percentage_error: 1850295168.0000\n",
      "Epoch 10/10\n",
      "3001/3001 [==============================] - 78s 26ms/step - loss: 377284128.0000 - binary_accuracy: 3.0236e-04 - mean_squared_error: 377284128.0000 - mean_absolute_percentage_error: 1820192640.0000\n",
      "step: 30 min loss: 377270560.0(-4093792.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 1000/1000 [00:57<00:00, 17.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3001/3001 [==============================] - 77s 26ms/step - loss: 377333952.0000 - binary_accuracy: 3.0252e-04 - mean_squared_error: 377333952.0000 - mean_absolute_percentage_error: 1784860160.0000\n",
      "Epoch 2/10\n",
      "3001/3001 [==============================] - 77s 26ms/step - loss: 377244832.0000 - binary_accuracy: 3.0236e-04 - mean_squared_error: 377244832.0000 - mean_absolute_percentage_error: 1749851392.0000\n",
      "Epoch 3/10\n",
      "3001/3001 [==============================] - 77s 26ms/step - loss: 376693664.0000 - binary_accuracy: 3.0249e-04 - mean_squared_error: 376693664.0000 - mean_absolute_percentage_error: 1860228224.0000\n",
      "Epoch 4/10\n",
      "3001/3001 [==============================] - 77s 26ms/step - loss: 376642240.0000 - binary_accuracy: 3.0249e-04 - mean_squared_error: 376642240.0000 - mean_absolute_percentage_error: 1721953664.0000\n",
      "Epoch 5/10\n",
      "1661/3001 [===============>..............] - ETA: 33s - loss: 376706016.0000 - binary_accuracy: 1.5074e-05 - mean_squared_error: 376706016.0000 - mean_absolute_percentage_error: 2869619456.0000"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "while loss >= 0.001:\n",
    "    step = step +epochs\n",
    "    log_dir = f'logs/fit/stp{step}_{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    \n",
    "    fitHistory = model.fit(dataset, epochs=epochs, batch_size=32, callbacks=[tensorboard_callback])\n",
    "    model.save(f'model/stp{step}_{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}', save_format=\"h5\")\n",
    "    \n",
    "    prew_loss = loss\n",
    "    loss = np.min(fitHistory.history['loss'])\n",
    "    \n",
    "    if step%100 == 0:\n",
    "        clear_output(wait=True)\n",
    "    \n",
    "    print(f'step: {step} min loss: {loss}({loss-prew_loss})')\n",
    "    \n",
    "    if prew_loss > loss:\n",
    "        predict()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
