{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.9.13 (main, Aug 25 2022, 23:26:10) \\n[GCC 11.2.0]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#math\n",
    "import numpy as np\n",
    "#capture\n",
    "import cv2\n",
    "import wave\n",
    "#utils\n",
    "from tqdm import tqdm\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-14 02:15:17.485382: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-14 02:15:17.671807: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-14 02:15:18.299186: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/cv2/../../lib64::/home/alex/miniconda3/envs/tf/lib/\n",
      "2022-10-14 02:15:18.299280: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/cv2/../../lib64::/home/alex/miniconda3/envs/tf/lib/\n",
      "2022-10-14 02:15:18.299292: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "#neural\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.keras import layers\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "system info\n",
    "-"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "for i in device_lib.list_local_devices():\n",
    "    print(f'{i.device_type}|{i.name} memory limit: {i.memory_limit}')\n",
    "    print(i.physical_device_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import data\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reshape(frame):\n",
    "    global WIDTH, HEIGHT\n",
    "    newframe = np.zeros(WIDTH*HEIGHT).reshape(HEIGHT, WIDTH)\n",
    "    if frame.shape[0] == HEIGHT and frame.shape[1] == WIDTH:\n",
    "        return frame\n",
    "    elif frame.shape[0] <= HEIGHT and frame.shape[1] <= WIDTH:\n",
    "        newframe[:frame.shape[0],:frame.shape[1]] = frame\n",
    "    elif frame.shape[0] <= HEIGHT:\n",
    "        print('HEIGHT')\n",
    "        newframe[:frame.shape[0],:] = frame[:, :WIDTH]\n",
    "    elif frame.shape[1] <= WIDTH:\n",
    "        print('WIDTH')\n",
    "        newframe[:,:frame.shape[1]] = frame[:HEIGHT, :]\n",
    "    else:\n",
    "        newframe = frame[:HEIGHT, :WIDTH]\n",
    "    return newframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "WIDTH = int(720)\n",
    "HEIGHT = int(625)\n",
    "\n",
    "def normilizeFrame(frame):\n",
    "    global WIDTH, HEIGHT\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #change dimentions(choose 1 of 2 options)\n",
    "    #frame = cv2.resize(frame, (WIDTH, HEIGHT), interpolation=cv2.INTER_NEAREST)\n",
    "    frame = reshape(frame)\n",
    "    \n",
    "    return frame\n",
    "    #return frame / 255.0\n",
    "\n",
    "fileName = 'testfiles/pal/testaud'\n",
    "\n",
    "cap = cv2.VideoCapture(fileName + '.avi')\n",
    "if (cap.isOpened()== False): \n",
    "  print(\"Error opening video stream or file\")\n",
    "\n",
    "ret, frame = cap.read()\n",
    "if not ret:\n",
    "    print('error reading frame')\n",
    "\n",
    "def getNext():\n",
    "    global WIDTH, HEIGHT\n",
    "    if cap.grab():\n",
    "        ret, frame = cap.retrieve()\n",
    "        if not ret:\n",
    "            print('error reading frame')\n",
    "            return False, np.zeros(WIDTH*HEIGHT).reshape(WIDTH, HEIGHT)\n",
    "        return True, normilizeFrame(frame)\n",
    "    else:\n",
    "        return False, np.zeros(WIDTH*HEIGHT).reshape(WIDTH, HEIGHT)\n",
    "\n",
    "gray = normilizeFrame(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2381\n",
      "1764\n"
     ]
    }
   ],
   "source": [
    "frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "print(frameCount)\n",
    "\n",
    "#tech calc\n",
    "\n",
    "#audio in pcm have 44100 samples in second per channel, respectively we have 88200 samples\n",
    "#per frame we have 44100/25(pal) = 1764 samples per frame(for single channel)\n",
    "\n",
    "samplesPerFrame = int(44100/cap.get(cv2.CAP_PROP_FPS))\n",
    "print(samplesPerFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!rm -rf ./dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!mkdir -p dataset\n",
    "!mkdir -p dataset/cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"./dataset/\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "bar = tqdm(total=frameCount, ncols=100)\n",
    "bar.set_description(\"Перегон одного говна в другое\")\n",
    "\n",
    "while ret:\n",
    "    cv2.imwrite(f'{dir}{int(cap.get(cv2.CAP_PROP_POS_FRAMES))}.png', gray)\n",
    "    \n",
    "    bar.update(1)\n",
    "    ret, gray = getNext()\n",
    "   \n",
    "cv2.imwrite(f'{dir}{int(cap.get(cv2.CAP_PROP_POS_FRAMES))+1}.png', np.zeros(WIDTH*HEIGHT).reshape(HEIGHT, WIDTH))\n",
    "\n",
    "import shutil\n",
    "shutil.copyfile(fileName + '.wav', f'{dir}audio.wav')\n",
    "\n",
    "bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-14 02:15:19.128619: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-14 02:15:19.754954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 910 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050, pci bus id: 0000:02:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "frames = len(list(tf.data.Dataset.list_files(f'{dir}*.png').as_numpy_iterator())) -1\n",
    "mainAudioFile = wave.open(f'{dir}audio.wav', mode='r')\n",
    "\n",
    "def gen():\n",
    "    global frames, mainAudioFile, samplesPerFrame\n",
    "    currentFrame = 1\n",
    "    \n",
    "    #audio\n",
    "    mainAudioFile.rewind()\n",
    "    \n",
    "    if not (mainAudioFile.getparams()[0] == 2 and mainAudioFile.getparams()[2] == 44100):\n",
    "        print('wrong audiofile params')\n",
    "        sys.exit(1)\n",
    "    \n",
    "    #video\n",
    "    \n",
    "    while currentFrame < frames:\n",
    "        #audio\n",
    "        frame = mainAudioFile.readframes(samplesPerFrame)\n",
    "        \n",
    "        if len(frame) < samplesPerFrame*2:\n",
    "            frame = frame + b'\\x00' * ((samplesPerFrame*4)-len(frame))\n",
    "        \n",
    "        #video\n",
    "        topframe=normilizeFrame(cv2.imread(f'{dir}{currentFrame}.png'))\n",
    "        bottomframe=normilizeFrame(cv2.imread(f'{dir}{currentFrame+1}.png'))\n",
    "        vframe = cv2.vconcat([topframe, bottomframe])\n",
    "        \n",
    "        yield vframe[np.newaxis is None,:,:], tf.io.decode_raw(frame, tf.int16, little_endian=True)\n",
    "        currentFrame = currentFrame+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Size must be declared for TensorArrays when eager execution is enabled.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tf\u001b[38;5;241m.\u001b[39mTensorArray(vframe)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/tensor_array_ops.py:1078\u001b[0m, in \u001b[0;36mTensorArray.__init__\u001b[0;34m(self, dtype, size, dynamic_size, clear_after_read, tensor_array_name, handle, flow, infer_shape, element_shape, colocate_with_first_write_call, name)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1077\u001b[0m   implementation \u001b[38;5;241m=\u001b[39m _GraphTensorArray\n\u001b[0;32m-> 1078\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_implementation \u001b[38;5;241m=\u001b[39m \u001b[43mimplementation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclear_after_read\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclear_after_read\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensor_array_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_array_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhandle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfer_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43melement_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43melement_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolocate_with_first_write_call\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolocate_with_first_write_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_implementation\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;241m=\u001b[39m weakref\u001b[38;5;241m.\u001b[39mref(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/tensor_array_ops.py:704\u001b[0m, in \u001b[0;36m_EagerTensorArray.__init__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    701\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensorArray handles are not supported when eager \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    702\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize must be declared for TensorArrays when eager \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    705\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    707\u001b[0m \u001b[38;5;66;03m# These attributes are not meaningful when eager is enabled, but some\u001b[39;00m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;66;03m# library functions (e.g., those in control_flow_ops.py) access them to\u001b[39;00m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;66;03m# create new tensor arrays; as such, we define them for the sake of\u001b[39;00m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;66;03m# compatibility.\u001b[39;00m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Size must be declared for TensorArrays when eager execution is enabled."
     ]
    }
   ],
   "source": [
    "tf.TensorArray(vframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=tf.data.Dataset.from_generator(\n",
    "    gen, \n",
    "    output_signature=(tf.TensorSpec(shape=(None, (HEIGHT*2), WIDTH), dtype=tf.uint8, name='image'),\n",
    "                      tf.TensorSpec(shape=(3528,), dtype=tf.int16, name='audio'),\n",
    "                      #tf.TensorSpec(shape=(1), dtype=tf.int32, name='frameNum')\n",
    "                     )\n",
    ").cache('./dataset/cache/')#.repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#testcode\n",
    "-"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "a=tf.io.decode_raw(d, tf.int16)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "a.numpy().tobytes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#create model\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = keras.Input(shape=((HEIGHT*2), WIDTH), name = 'image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.layers.Rescaling(1./255, name='normalize')(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1\n",
    "x = tf.keras.layers.Conv1D(128, 3, activation='relu', name=f'conv1d_{lr}', input_shape=(WIDTH, (HEIGHT*2)))(x)\n",
    "x = tf.keras.layers.MaxPooling1D(name=f'MaxPooling1D_{lr}')(x)\n",
    "lr = lr + 1\n",
    "x = tf.keras.layers.Conv1D(128, 3, activation='relu', name=f'conv1d_{lr}', input_shape=(WIDTH, (HEIGHT*2)))(x)\n",
    "x = tf.keras.layers.MaxPooling1D(name=f'MaxPooling1D_{lr}')(x)\n",
    "lr = lr + 1\n",
    "x = tf.keras.layers.Conv1D(128, 3, activation='relu', name=f'conv1d_{lr}', input_shape=(WIDTH, (HEIGHT*2)))(x)\n",
    "x = tf.keras.layers.MaxPooling1D(name=f'MaxPooling1D_{lr}')(x)\n",
    "lr = lr + 1\n",
    "x = tf.keras.layers.Conv1D(128, 3, activation='relu', name=f'conv1d_{lr}', input_shape=(WIDTH, (HEIGHT*2)))(x)\n",
    "x = tf.keras.layers.MaxPooling1D(name=f'MaxPooling1D_{lr}')(x)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x = tf.keras.layers.Conv2D(128, 3, activation='relu', name='conv2d_1')(x)\n",
    "x = tf.keras.layers.MaxPooling2D(name='MaxPooling2D_1')(x)\n",
    "x = tf.keras.layers.Conv2D(128, 3, activation='relu', name='conv2d_')(x)\n",
    "x = tf.keras.layers.MaxPooling2D(name='MaxPooling2D_2')(x)\n",
    "x = tf.keras.layers.Conv2D(128, 3, activation='relu', name='conv2d_3')(x)\n",
    "x = tf.keras.layers.MaxPooling2D(name='MaxPooling2D_3')(x)\n",
    "x = tf.keras.layers.Conv2D(128, 3, activation='relu', name='conv2d_4')(x)\n",
    "x = tf.keras.layers.MaxPooling2D(name='MaxPooling2D_4')(x)\n",
    "x = tf.keras.layers.Conv2D(128, 3, activation='relu', name='conv2d_5')(x)\n",
    "x = tf.keras.layers.MaxPooling2D(name='MaxPooling2D_5')(x)\n",
    "x = tf.keras.layers.Conv2D(128, 3, activation='relu', name='conv2d_6')(x)\n",
    "x = tf.keras.layers.MaxPooling2D(name='MaxPooling2D_6')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.layers.Flatten(name='Flatten')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = tf.keras.layers.Dense((samplesPerFrame*2), activation='relu', bias_initializer='zeros', use_bias=True, name='layer_1')(x)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x = tf.keras.layers.Reshape((samplesPerFrame, 2), input_shape=(None, samplesPerFrame*2))(x)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x = tf.squeeze(x, axis=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = tf.keras.layers.Dense((samplesPerFrame*2), activation='relu', bias_initializer='zeros', use_bias=True, name='audio')(x)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "output = tf.round(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " image (InputLayer)          [(None, 1250, 720)]       0         \n",
      "                                                                 \n",
      " normalize (Rescaling)       (None, 1250, 720)         0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 1248, 128)         276608    \n",
      "                                                                 \n",
      " MaxPooling1D_1 (MaxPooling1  (None, 624, 128)         0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 622, 128)          49280     \n",
      "                                                                 \n",
      " MaxPooling1D_2 (MaxPooling1  (None, 311, 128)         0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 309, 128)          49280     \n",
      "                                                                 \n",
      " MaxPooling1D_3 (MaxPooling1  (None, 154, 128)         0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 152, 128)          49280     \n",
      "                                                                 \n",
      " MaxPooling1D_4 (MaxPooling1  (None, 76, 128)          0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " Flatten (Flatten)           (None, 9728)              0         \n",
      "                                                                 \n",
      " layer_1 (Dense)             (None, 3528)              34323912  \n",
      "                                                                 \n",
      " audio (Dense)               (None, 3528)              12450312  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 47,198,672\n",
      "Trainable params: 47,198,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "model = keras.Model(input, output)\n",
    "model.summary()\n",
    "\n",
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file=\"model.png\",\n",
    "    show_shapes=True,\n",
    "    show_dtype=False,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=True,\n",
    "    dpi=96,\n",
    "    layer_range=None,\n",
    "    show_layer_activations=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compile and learn\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-14 02:15:20.636088: W tensorflow/core/kernels/data/cache_dataset_ops.cc:296] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2022-10-14 02:15:22.735433: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8500\n",
      "2022-10-14 02:15:23.179985: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2022-10-14 02:15:23.180813: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at conv_ops.cc:1134 : NOT_FOUND: No algorithm worked!  Error messages:\n",
      "  Profiling failure on CUDNN engine 1: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\n",
      "in tensorflow/stream_executor/cuda/cuda_dnn.cc(4023): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd_.handle(), input_data.opaque(), filter_.handle(), filter_data.opaque(), conv_.handle(), ToConvForwardAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, output_nd_.handle(), output_data.opaque())'\n",
      "  Profiling failure on CUDNN engine 0: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\n",
      "in tensorflow/stream_executor/cuda/cuda_dnn.cc(4023): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd_.handle(), input_data.opaque(), filter_.handle(), filter_data.opaque(), conv_.handle(), ToConvForwardAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, output_nd_.handle(), output_data.opaque())'\n",
      "  Profiling failure on CUDNN engine 2: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\n",
      "in tensorflow/stream_executor/cuda/cuda_dnn.cc(4023): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd_.handle(), input_data.opaque(), filter_.handle(), filter_data.opaque(), conv_.handle(), ToConvForwardAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, output_nd_.handle(), output_data.opaque())'\n",
      "  Profiling failure on CUDNN engine 5: UNKNOWN: CUDNN_STATUS_INTERNAL_ERROR\n",
      "in tensorflow/stream_executor/cuda/cuda_dnn.cc(4023): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd_.handle(), input_data.opaque(), filter_.handle(), filter_data.opaque(), conv_.handle(), ToConvForwardAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, output_nd_.handle(), output_data.opaque())'\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Graph execution error:\n\nDetected at node 'model/conv1d_1/Conv1D' defined at (most recent call last):\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/traitlets/config/application.py\", line 978, in launch_instance\n      app.start()\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_cell\n      result = self._run_cell(\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2940, in _run_cell\n      return runner(coro)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3139, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3318, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_2758590/7648335.py\", line 3, in <module>\n      fitHistory = model.fit(dataset, epochs=1, batch_size=1)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/keras/layers/convolutional/base_conv.py\", line 283, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/keras/layers/convolutional/base_conv.py\", line 255, in convolution_op\n      return tf.nn.convolution(\nNode: 'model/conv1d_1/Conv1D'\nNo algorithm worked!  Error messages:\n  Profiling failure on CUDNN engine 1: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4023): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd_.handle(), input_data.opaque(), filter_.handle(), filter_data.opaque(), conv_.handle(), ToConvForwardAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, output_nd_.handle(), output_data.opaque())'\n  Profiling failure on CUDNN engine 0: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4023): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd_.handle(), input_data.opaque(), filter_.handle(), filter_data.opaque(), conv_.handle(), ToConvForwardAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, output_nd_.handle(), output_data.opaque())'\n  Profiling failure on CUDNN engine 2: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4023): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd_.handle(), input_data.opaque(), filter_.handle(), filter_data.opaque(), conv_.handle(), ToConvForwardAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, output_nd_.handle(), output_data.opaque())'\n  Profiling failure on CUDNN engine 5: UNKNOWN: CUDNN_STATUS_INTERNAL_ERROR\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4023): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd_.handle(), input_data.opaque(), filter_.handle(), filter_data.opaque(), conv_.handle(), ToConvForwardAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, output_nd_.handle(), output_data.opaque())'\n\t [[{{node model/conv1d_1/Conv1D}}]] [Op:__inference_train_function_3604]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m loss \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m:\n\u001b[0;32m----> 3\u001b[0m     fitHistory \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(dataset, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m     loss \u001b[38;5;241m=\u001b[39m fitHistory\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Graph execution error:\n\nDetected at node 'model/conv1d_1/Conv1D' defined at (most recent call last):\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/traitlets/config/application.py\", line 978, in launch_instance\n      app.start()\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_cell\n      result = self._run_cell(\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2940, in _run_cell\n      return runner(coro)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3139, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3318, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_2758590/7648335.py\", line 3, in <module>\n      fitHistory = model.fit(dataset, epochs=1, batch_size=1)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/keras/layers/convolutional/base_conv.py\", line 283, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/home/alex/miniconda3/envs/tf/lib/python3.9/site-packages/keras/layers/convolutional/base_conv.py\", line 255, in convolution_op\n      return tf.nn.convolution(\nNode: 'model/conv1d_1/Conv1D'\nNo algorithm worked!  Error messages:\n  Profiling failure on CUDNN engine 1: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4023): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd_.handle(), input_data.opaque(), filter_.handle(), filter_data.opaque(), conv_.handle(), ToConvForwardAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, output_nd_.handle(), output_data.opaque())'\n  Profiling failure on CUDNN engine 0: UNKNOWN: CUDNN_STATUS_ALLOC_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4023): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd_.handle(), input_data.opaque(), filter_.handle(), filter_data.opaque(), conv_.handle(), ToConvForwardAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, output_nd_.handle(), output_data.opaque())'\n  Profiling failure on CUDNN engine 2: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4023): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd_.handle(), input_data.opaque(), filter_.handle(), filter_data.opaque(), conv_.handle(), ToConvForwardAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, output_nd_.handle(), output_data.opaque())'\n  Profiling failure on CUDNN engine 5: UNKNOWN: CUDNN_STATUS_INTERNAL_ERROR\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4023): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd_.handle(), input_data.opaque(), filter_.handle(), filter_data.opaque(), conv_.handle(), ToConvForwardAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, output_nd_.handle(), output_data.opaque())'\n\t [[{{node model/conv1d_1/Conv1D}}]] [Op:__inference_train_function_3604]"
     ]
    }
   ],
   "source": [
    "loss = 1\n",
    "while loss >= 0.01:\n",
    "    fitHistory = model.fit(dataset, epochs=1, batch_size=1)\n",
    "    loss = fitHistory.history['loss'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelP2.save(\"model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
