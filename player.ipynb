{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40977493-f410-4ce9-abf7-6e491a45158e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from collections import deque\n",
    "import wave, struct\n",
    "import cProfile, re\n",
    "#cProfile.run('re.compile(\"foo|bar\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a8e2127-c8db-4248-8031-b562e351cb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = int(720/4)\n",
    "\n",
    "def normilizeFrame(frame):\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    #cv2.imwrite(\"gray.png\", frame)\n",
    "    frame = cv2.resize(frame, (WIDTH, frame.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "    return frame\n",
    "\n",
    "fileName = 'testfiles/sine1khz_30s'\n",
    "\n",
    "cap = cv2.VideoCapture(fileName + '.avi')\n",
    "if (cap.isOpened()== False): \n",
    "  print(\"Error opening video stream or file\")\n",
    "\n",
    "ret, frame = cap.read()\n",
    "if not ret:\n",
    "    print('error reading frame')\n",
    "\n",
    "gray = normilizeFrame(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06135b69-dc4c-4aa3-8b16-314a57520e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720.0\n",
      "625.0\n",
      "751.0\n"
     ]
    }
   ],
   "source": [
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "frameCount = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "print(height)\n",
    "print(frameCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7e9464f-925e-45e0-b04c-e18f7b66c1d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-23 23:16:31.980613: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-23 23:16:32.744463: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 774 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050, pci bus id: 0000:02:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3edbd10f-1310-4411-9d60-b956d2df77ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deinterlase(frame):\n",
    "    even_fields=frame[::2,:];\n",
    "    odd_fields=frame[1::2,:];\n",
    "    return np.concatenate((even_fields, odd_fields), axis=0)\n",
    "\n",
    "bufL0 = deque()\n",
    "bufR0 = deque()\n",
    "bufL1 = deque()\n",
    "bufR1 = deque()\n",
    "bufL2 = deque()\n",
    "emptyLine = np.zeros(14, dtype=bool)\n",
    "\n",
    "#kluge init queues\n",
    "for i in range((16*5)-1):\n",
    "    bufL0.append(emptyLine)\n",
    "\n",
    "for i in range((16*4)-1):\n",
    "    bufR0.append(emptyLine)\n",
    "\n",
    "for i in range((16*3)-1):\n",
    "    bufL1.append(emptyLine)\n",
    "\n",
    "for i in range((16*2)-1):\n",
    "    bufR1.append(emptyLine)\n",
    "    \n",
    "for i in range(16-1):\n",
    "    bufL2.append(emptyLine)\n",
    "\n",
    "def bitsToInt(bits):\n",
    "    a = 0\n",
    "    for i in range(0, len(bits)):\n",
    "        a = bits[i] | a << 1\n",
    "    return a\n",
    "    \n",
    "def deinterlive(block):\n",
    "    block = block[4:88]\n",
    "    \n",
    "    bufL0.append(block[:14])\n",
    "    bufR0.append(block[14:28])\n",
    "    bufL1.append(block[28:42])\n",
    "    bufR1.append(block[42:56])\n",
    "    bufL2.append(block[56:70])\n",
    "    \n",
    "    return bufL0.popleft(), bufR0.popleft(), bufL1.popleft(), bufR1.popleft(), bufL2.popleft(), block[70:84] #L0, R0, L1, R1, L2, R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66739185-c929-48b6-9c3d-2d7572703548",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "decoding:   0%|                                                                                   | 0/751.0 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "bar = tqdm(total=frameCount - (cap.get(cv2.CAP_PROP_POS_FRAMES) -1))\n",
    "bar.set_description(\"decoding\")\n",
    "file = wave.open(fileName + '.wav', mode='w')\n",
    "file.setnchannels(2) \n",
    "file.setsampwidth(2)\n",
    "file.setframerate(44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e3066d4-ca79-4627-a912-6e1b10dc4954",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#def a():\n",
    "while True:\n",
    "    bar.update(1)\n",
    "    if cap.grab():\n",
    "        ret, frame = cap.retrieve()\n",
    "        \n",
    "        if not ret:\n",
    "            print('error reading frame')\n",
    "            break\n",
    "                \n",
    "        gray = normilizeFrame(frame)\n",
    "        #cv2.imwrite(\"gray_norm.png\", gray)\n",
    "        \n",
    "        gray = deinterlase(gray)\n",
    "        \n",
    "        #cv2.imwrite(\"gray_deint.png\", gray)\n",
    "        \n",
    "        service, data = model.predict(gray, verbose=0)\n",
    "        service = service > 0.5\n",
    "        data = data > 0.5\n",
    "        \n",
    "        audioFrame = bytearray()\n",
    "        \n",
    "        for i in range(len(service)):\n",
    "            if service[i][0]:\n",
    "                L0, R0, L1, R1, L2, R2 = deinterlive(data[i])\n",
    "                audioFrame += struct.pack('<H', (bitsToInt(L0) << 2))\n",
    "                audioFrame += struct.pack('<H', (bitsToInt(R0) << 2))\n",
    "                audioFrame += struct.pack('<H', (bitsToInt(L1) << 2))\n",
    "                audioFrame += struct.pack('<H', (bitsToInt(R1) << 2))\n",
    "                audioFrame += struct.pack('<H', (bitsToInt(L2) << 2))\n",
    "                audioFrame += struct.pack('<H', (bitsToInt(R2) << 2))\n",
    "                \n",
    "        
    "        file.writeframes(audioFrame)\n",
    "    if cap.get(cv2.CAP_PROP_POS_FRAMES) == frameCount:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "524af401-46a8-4142-89bd-c2e73d1a839b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cProfile.run('a()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f33b04-734e-440e-b036-a53957c7abcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
