{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 18044312295152168282\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6475376230\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 3924771105735373762\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:03:00.0, compute capability: 6.1\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Raspakek data: 100%|█████████████████████████████████████████████████████████████████████| 4/4 [00:14<00:00,  3.74s/it]\n"
     ]
    }
   ],
   "source": [
    "bar = tqdm(total=4)\n",
    "bar.set_description(\"Raspakek data\")\n",
    "\n",
    "inputLines = np.load('traindata/inputLines.npy')/256\n",
    "bar.update(1)\n",
    "\n",
    "service = np.load('traindata/service.npy')\n",
    "bar.update(1)\n",
    "\n",
    "binaryData = np.load('traindata/binaryData.npy')\n",
    "bar.update(1)\n",
    "\n",
    "#blockL0 = np.load('traindata/blockL0.npy')\n",
    "#bar.update(1)\n",
    "#\n",
    "#blockR0 = np.load('traindata/blockR0.npy')\n",
    "#bar.update(1)\n",
    "#\n",
    "#blockL1 = np.load('traindata/blockL1.npy')\n",
    "#bar.update(1)\n",
    "#\n",
    "#blockR1 = np.load('traindata/blockR1.npy')\n",
    "#bar.update(1)\n",
    "#\n",
    "#blockL2 = np.load('traindata/blockL2.npy')\n",
    "#bar.update(1)\n",
    "#\n",
    "#blockR2 = np.load('traindata/blockR2.npy')\n",
    "#bar.update(1)\n",
    "\n",
    "#remove all data after 100000 pos\n",
    "if False:\n",
    "    remAftr = 100000\n",
    "    inputLines = inputLines[:remAftr]\n",
    "    service = service[:remAftr]\n",
    "    blockL0 = blockL0[:remAftr]\n",
    "    blockR0 = blockR0[:remAftr]\n",
    "    blockL1 = blockL1[:remAftr]\n",
    "    blockR1 = blockR1[:remAftr]\n",
    "    blockL2 = blockL2[:remAftr]\n",
    "    blockR2 = blockR2[:remAftr]\n",
    "\n",
    "#target_data = {'service': service, 'blockL0': blockL0, 'blockR0':blockR0, 'blockL1':blockL1, 'blockR1':blockR1, 'blockL2':blockL2, 'blockR2':blockR2}\n",
    "target_data = {'service': service, 'binaryData':binaryData}\n",
    "bar.update(1)\n",
    "bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.46875   , 0.58203125, 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.2109375 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.265625  , 0.58203125, 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.4140625 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.52734375, 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.58203125, 0.15234375, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.22265625, 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.58203125, 0.4609375 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.01953125, 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.58203125, 0.58203125, 0.09765625, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07421875, 0.58203125, 0.58203125,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.140625  , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.3359375 , 0.58203125,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.34765625, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.1328125 , 0.58203125,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.546875  , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.390625  ,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.58203125, 0.2890625 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.0859375 ,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.02734375, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.453125  , 0.58203125, 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.234375  , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.24609375, 0.58203125, 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.43359375, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.40625   , 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.58203125, 0.2734375 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.19921875, 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.58203125, 0.48046875, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.56640625, 0.58203125, 0.58203125,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.58203125, 0.58203125, 0.5234375 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.51953125, 0.58203125,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.16015625, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.109375  , 0.58203125,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.5703125 , 0.00390625,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.47265625,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.58203125, 0.30859375,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.16796875,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.58203125, 0.51171875,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.22265625, 0.58203125, 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.45703125, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.0234375 , 0.58203125, 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.58203125, 0.1953125 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.28125   , 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.58203125, 0.3984375 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.54296875, 0.58203125, 0.58203125,\n",
       "       0.58203125, 0.58203125, 0.13671875, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.23828125, 0.58203125, 0.58203125,\n",
       "       0.58203125, 0.58203125, 0.44140625, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.03125   , 0.58203125, 0.58203125,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.08203125, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.29296875, 0.58203125,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.38671875, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.1484375 ,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.0703125 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.40625   , 0.58203125, 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.2734375 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.1015625 , 0.58203125, 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.1015625 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.375     , 0.58203125,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.58203125, 0.25      ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.12890625,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.58203125, 0.5546875 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.18359375, 0.58203125, 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.49609375, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.34375   , 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.58203125, 0.3359375 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.13671875, 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.58203125, 0.54296875, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.5       , 0.58203125, 0.58203125,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.58203125, 0.58203125, 0.28125   , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.5546875 , 0.58203125,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.125     , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.35546875, 0.58203125,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.58203125, 0.58203125,\n",
       "       0.58203125, 0.58203125, 0.58203125, 0.4296875 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.875     ,\n",
       "       0.9921875 , 0.9921875 , 0.9921875 , 0.9921875 , 0.9921875 ,\n",
       "       0.9921875 , 0.9921875 , 0.9921875 , 0.9921875 , 0.9921875 ,\n",
       "       0.9921875 , 0.9921875 , 0.9921875 , 0.9921875 , 0.9921875 ,\n",
       "       0.9921875 , 0.9921875 , 0.9921875 , 0.9921875 , 0.8046875 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputLines[5151]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True, False, False,  True, False, False,  True,\n",
       "       False,  True, False, False, False, False,  True,  True, False,\n",
       "        True, False,  True, False, False,  True, False, False,  True,\n",
       "       False,  True, False,  True, False, False, False,  True, False,\n",
       "        True, False,  True,  True,  True,  True,  True, False,  True,\n",
       "       False, False, False,  True, False,  True,  True, False,  True,\n",
       "       False, False, False, False,  True, False,  True,  True, False,\n",
       "        True, False, False,  True, False, False,  True, False,  True,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "        True,  True, False,  True, False, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False,  True,  True,  True,  True,  True,  True, False,\n",
       "       False,  True, False, False, False, False,  True, False, False,\n",
       "       False,  True, False,  True, False,  True,  True, False, False,\n",
       "       False,  True, False,  True,  True, False, False,  True,  True,\n",
       "        True,  True])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binaryData[5151]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service[5151]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 720), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\") at layer \"dense_4\". The following previous layers were accessed without issue: []",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m binaryData \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m137\u001b[39m , activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinaryData\u001b[39m\u001b[38;5;124m'\u001b[39m)(binaryData)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#blockL0 = layers.Dense(16, activation='sigmoid', use_bias=True, bias_initializer='zeros', name='blockL0')(x)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#blockR0 = layers.Dense(16, activation='sigmoid', use_bias=True, bias_initializer='zeros', name='blockR0')(x)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#blockL1 = layers.Dense(16, activation='sigmoid', use_bias=True, bias_initializer='zeros', name='blockL1')(x)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m \n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#model = keras.Model(input, [service, blockL0, blockR0, blockL1, blockR1, blockL2, blockR2])\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mservice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinaryData\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[0;32m     22\u001b[0m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mplot_model(\n\u001b[0;32m     23\u001b[0m     model,\n\u001b[0;32m     24\u001b[0m     to_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.png\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m     show_layer_activations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     33\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py:629\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 629\u001b[0m   result \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\functional.py:146\u001b[0m, in \u001b[0;36mFunctional.__init__\u001b[1;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m([functional_utils\u001b[38;5;241m.\u001b[39mis_input_keras_tensor(t)\n\u001b[0;32m    144\u001b[0m               \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(inputs)]):\n\u001b[0;32m    145\u001b[0m     inputs, outputs \u001b[38;5;241m=\u001b[39m functional_utils\u001b[38;5;241m.\u001b[39mclone_graph_nodes(inputs, outputs)\n\u001b[1;32m--> 146\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_graph_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py:629\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 629\u001b[0m   result \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\functional.py:229\u001b[0m, in \u001b[0;36mFunctional._init_graph_network\u001b[1;34m(self, inputs, outputs)\u001b[0m\n\u001b[0;32m    226\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_coordinates\u001b[38;5;241m.\u001b[39mappend((layer, node_index, tensor_index))\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# Keep track of the network's nodes and layers.\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m nodes, nodes_by_depth, layers, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_map_graph_network\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_nodes \u001b[38;5;241m=\u001b[39m nodes\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes_by_depth \u001b[38;5;241m=\u001b[39m nodes_by_depth\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\functional.py:1036\u001b[0m, in \u001b[0;36m_map_graph_network\u001b[1;34m(inputs, outputs)\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(node\u001b[38;5;241m.\u001b[39mkeras_inputs):\n\u001b[0;32m   1035\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mid\u001b[39m(x) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m computable_tensors:\n\u001b[1;32m-> 1036\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1037\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGraph disconnected: cannot obtain value for tensor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1038\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mat layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. The following previous layers \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1039\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwere accessed without issue: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayers_with_complete_input\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(node\u001b[38;5;241m.\u001b[39moutputs):\n\u001b[0;32m   1041\u001b[0m   computable_tensors\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(x))\n",
      "\u001b[1;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 720), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\") at layer \"dense_4\". The following previous layers were accessed without issue: []"
     ]
    }
   ],
   "source": [
    "input = keras.Input(720, )\n",
    "x = layers.Dense(137, activation='linear', use_bias=True, bias_initializer='zeros')(input)\n",
    "#x = layers.Dropout(0.1)(x)\n",
    "x = layers.Dense(137, activation='linear', use_bias=True, bias_initializer='zeros')(x)\n",
    "\n",
    "service = layers.Dense(2 , activation='sigmoid', name='service')(service)\n",
    "tf.math.sigmoid(x)\n",
    "tf.math.sigmoid(x)\n",
    "binaryData = layers.Dense(137 , activation='sigmoid', name='binaryData')(binaryData)\n",
    "#blockL0 = layers.Dense(16, activation='sigmoid', use_bias=True, bias_initializer='zeros', name='blockL0')(x)\n",
    "#blockR0 = layers.Dense(16, activation='sigmoid', use_bias=True, bias_initializer='zeros', name='blockR0')(x)\n",
    "#blockL1 = layers.Dense(16, activation='sigmoid', use_bias=True, bias_initializer='zeros', name='blockL1')(x)\n",
    "#blockR1 = layers.Dense(16, activation='sigmoid', use_bias=True, bias_initializer='zeros', name='blockR1')(x)\n",
    "#blockL2 = layers.Dense(16, activation='sigmoid', use_bias=True, bias_initializer='zeros', name='blockL2')(x)\n",
    "#blockR2 = layers.Dense(16, activation='sigmoid', use_bias=True, bias_initializer='zeros', name='blockR2')(x)\n",
    "\n",
    "\n",
    "#model = keras.Model(input, [service, blockL0, blockR0, blockL1, blockR1, blockL2, blockR2])\n",
    "model = keras.Model(input, [service, binaryData])\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file=\"model.png\",\n",
    "    show_shapes=True,\n",
    "    show_dtype=False,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=True,\n",
    "    dpi=96,\n",
    "    layer_range=None,\n",
    "    show_layer_activations=True,\n",
    ")\n",
    "\n",
    "#visualizer(model, format='png', view=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "29223/29223 [==============================] - 311s 11ms/step - loss: 0.0734 - service_loss: 0.0033 - binaryData_loss: 0.0701 - service_binary_accuracy: 0.9998 - binaryData_binary_accuracy: 0.9031\n",
      "Epoch 2/3\n",
      "29223/29223 [==============================] - 355s 12ms/step - loss: 0.0436 - service_loss: 6.4871e-09 - binaryData_loss: 0.0436 - service_binary_accuracy: 1.0000 - binaryData_binary_accuracy: 0.9423\n",
      "Epoch 3/3\n",
      " 8664/29223 [=======>......................] - ETA: 4:21 - loss: 0.0381 - service_loss: 1.9777e-09 - binaryData_loss: 0.0381 - service_binary_accuracy: 1.0000 - binaryData_binary_accuracy: 0.9501"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputLines\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2954\u001b[0m   (graph_function,\n\u001b[0;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1856\u001b[0m     args,\n\u001b[0;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1858\u001b[0m     executing_eagerly)\n\u001b[0;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(inputLines, target_data, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[1.5477517e-04, 7.7058168e-05]], dtype=float32), array([[1.07869343e-03, 5.45098956e-05, 1.03853061e-03, 5.92705182e-05,\n",
      "        8.54914106e-05, 3.71981441e-04, 3.40228667e-04, 7.58250884e-04,\n",
      "        1.18048119e-05, 1.35251757e-04, 1.03420613e-03, 1.17235782e-03,\n",
      "        1.84291101e-03, 3.20153390e-06, 9.52157716e-05, 1.07106019e-03,\n",
      "        8.88990962e-06, 3.25700239e-05, 3.42334679e-04, 2.98509229e-04,\n",
      "        5.07144199e-04, 3.61893704e-04, 7.14776106e-05, 7.02425081e-04,\n",
      "        1.77428490e-04, 1.05157058e-04, 5.81831337e-05, 1.47321471e-03,\n",
      "        2.23033999e-06, 3.44207929e-03, 1.10956622e-04, 3.48267822e-05,\n",
      "        1.49982356e-04, 2.91654083e-04, 2.38680252e-04, 4.45689540e-04,\n",
      "        1.56500813e-04, 2.07484671e-04, 9.62918348e-05, 9.57095122e-04,\n",
      "        1.12620575e-04, 4.44069592e-05, 4.07084415e-04, 5.38571066e-06,\n",
      "        1.45125559e-05, 1.11276947e-03, 1.07208900e-04, 4.60879732e-04,\n",
      "        1.73590146e-04, 9.36910292e-05, 5.89446699e-06, 9.76792580e-05,\n",
      "        1.00136269e-04, 2.50042975e-03, 6.08351547e-04, 1.09412591e-03,\n",
      "        8.17781314e-04, 2.03400399e-04, 2.68657004e-05, 2.39379769e-05,\n",
      "        2.36552485e-04, 3.36523626e-05, 3.86983680e-04, 1.83295517e-03,\n",
      "        4.97125380e-04, 3.92280490e-04, 1.22107507e-04, 4.79727576e-04,\n",
      "        3.30538198e-04, 9.68159002e-04, 2.27539858e-04, 2.94039550e-04,\n",
      "        1.42529584e-03, 3.38040001e-04, 2.46594427e-04, 4.73624277e-05,\n",
      "        2.51235324e-05, 9.00704064e-04, 3.18228989e-03, 5.02885785e-04,\n",
      "        4.51404863e-04, 2.47119926e-03, 2.01875795e-04, 1.89777231e-03,\n",
      "        3.44328873e-04, 1.54993131e-06, 6.83120970e-06, 2.64746323e-05,\n",
      "        2.61613750e-04, 2.57072606e-05, 4.86847159e-04, 4.40606800e-06,\n",
      "        6.74749084e-04, 9.31215356e-04, 1.47246028e-04, 4.92452345e-05,\n",
      "        3.27206944e-04, 1.14602528e-06, 4.92287072e-05, 4.70095547e-05,\n",
      "        4.11512534e-04, 6.59943791e-04, 7.77822715e-05, 1.21061725e-03,\n",
      "        1.23512773e-05, 3.34745797e-04, 1.07107556e-03, 2.48746335e-04,\n",
      "        1.16091796e-04, 2.71568570e-04, 1.76705398e-05, 1.15269946e-03,\n",
      "        1.11105372e-04, 6.23578990e-06, 1.77200069e-04, 4.85547253e-06,\n",
      "        8.60954402e-04, 2.76067352e-04, 6.95389172e-04, 4.01763682e-05,\n",
      "        7.92578212e-05, 5.06121141e-04, 1.08319661e-03, 7.17215240e-04,\n",
      "        5.08627272e-04, 1.47866237e-03, 6.35287006e-06, 1.18827465e-05,\n",
      "        3.09059396e-04, 7.50691688e-05, 5.23885537e-04, 1.41366436e-05,\n",
      "        7.91873317e-05, 1.05159136e-03, 1.04491541e-03, 1.02980831e-03,\n",
      "        1.03010074e-03]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(np.array([inputLines[5]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
