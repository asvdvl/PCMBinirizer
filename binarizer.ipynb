{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 8561080726515263681\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 772538368\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 6905870099506070564\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1050, pci bus id: 0000:02:00.0, compute capability: 6.1\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-23 16:02:57.272107: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-23 16:02:58.131305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:0 with 736 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050, pci bus id: 0000:02:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Raspakek data: 100%|██████████████████████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  1.20s/it]\n"
     ]
    }
   ],
   "source": [
    "bar = tqdm(total=4)\n",
    "bar.set_description(\"Raspakek data\")\n",
    "\n",
    "inputLines = np.load('traindata/inputLines.npy')/256\n",
    "bar.update(1)\n",
    "\n",
    "service = np.load('traindata/service.npy')\n",
    "bar.update(1)\n",
    "\n",
    "binaryData = np.load('traindata/binaryData.npy')\n",
    "bar.update(1)\n",
    "\n",
    "#blockL0 = np.load('traindata/blockL0.npy')\n",
    "#bar.update(1)\n",
    "#\n",
    "#blockR0 = np.load('traindata/blockR0.npy')\n",
    "#bar.update(1)\n",
    "#\n",
    "#blockL1 = np.load('traindata/blockL1.npy')\n",
    "#bar.update(1)\n",
    "#\n",
    "#blockR1 = np.load('traindata/blockR1.npy')\n",
    "#bar.update(1)\n",
    "#\n",
    "#blockL2 = np.load('traindata/blockL2.npy')\n",
    "#bar.update(1)\n",
    "#\n",
    "#blockR2 = np.load('traindata/blockR2.npy')\n",
    "#bar.update(1)\n",
    "\n",
    "#target_data = {'service': service, 'blockL0': blockL0, 'blockR0':blockR0, 'blockL1':blockL1, 'blockR1':blockR1, 'blockL2':blockL2, 'blockR2':blockR2}\n",
    "target_data = {'service': service, 'binaryData':binaryData}\n",
    "bar.update(1)\n",
    "bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all data after 100000 pos\n",
    "if False:\n",
    "    remAftr = 100000\n",
    "    inputLines = inputLines[:remAftr]\n",
    "    service = service[:remAftr]\n",
    "    binaryData = binaryData[:remAftr]\n",
    "    #blockL0 = blockL0[:remAftr]\n",
    "    #blockR0 = blockR0[:remAftr]\n",
    "    #blockL1 = blockL1[:remAftr]\n",
    "    #blockR1 = blockR1[:remAftr]\n",
    "    #blockL2 = blockL2[:remAftr]\n",
    "    #blockR2 = blockR2[:remAftr]\n",
    "    target_data = {'service': service, 'binaryData':binaryData}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(935123, 180)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputLines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True, False, False,  True, False, False,  True,\n",
       "       False,  True, False, False, False, False,  True,  True, False,\n",
       "        True, False,  True, False, False,  True, False, False,  True,\n",
       "       False,  True, False,  True, False, False, False,  True, False,\n",
       "        True, False,  True,  True,  True,  True,  True, False,  True,\n",
       "       False, False, False,  True, False,  True,  True, False,  True,\n",
       "       False, False, False, False,  True, False,  True,  True, False,\n",
       "        True, False, False,  True, False, False,  True, False,  True,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "        True,  True, False,  True, False, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False,  True,  True,  True,  True,  True,  True, False,\n",
       "       False,  True, False, False, False, False,  True, False, False,\n",
       "       False,  True, False,  True, False,  True,  True, False, False,\n",
       "       False,  True, False,  True,  True, False, False,  True,  True,\n",
       "        True,  True])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binaryData[5151]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service[5151]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-23 16:03:13.888666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 736 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050, pci bus id: 0000:02:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 180)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 137)          24797       ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 137)          18906       ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " service (Dense)                (None, 2)            276         ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " binaryData (Dense)             (None, 137)          18906       ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 62,885\n",
      "Trainable params: 62,885\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "input = keras.Input(180, )\n",
    "x = layers.Dense(137, activation='linear', use_bias=True, bias_initializer='zeros')(input)\n",
    "#x = layers.Dropout(0.1)(x)\n",
    "x = layers.Dense(137, activation='linear', use_bias=True, bias_initializer='zeros')(x)\n",
    "\n",
    "service = layers.Dense(2 , activation='sigmoid', name='service')(x)\n",
    "binaryData = layers.Dense(137 , activation='sigmoid', name='binaryData')(x)\n",
    "#blockL0 = layers.Dense(16, activation='sigmoid', use_bias=True, bias_initializer='zeros', name='blockL0')(x)\n",
    "#blockR0 = layers.Dense(16, activation='sigmoid', use_bias=True, bias_initializer='zeros', name='blockR0')(x)\n",
    "#blockL1 = layers.Dense(16, activation='sigmoid', use_bias=True, bias_initializer='zeros', name='blockL1')(x)\n",
    "#blockR1 = layers.Dense(16, activation='sigmoid', use_bias=True, bias_initializer='zeros', name='blockR1')(x)\n",
    "#blockL2 = layers.Dense(16, activation='sigmoid', use_bias=True, bias_initializer='zeros', name='blockL2')(x)\n",
    "#blockR2 = layers.Dense(16, activation='sigmoid', use_bias=True, bias_initializer='zeros', name='blockR2')(x)\n",
    "\n",
    "\n",
    "#model = keras.Model(input, [service, blockL0, blockR0, blockL1, blockR1, blockL2, blockR2])\n",
    "model = keras.Model(input, [service, binaryData])\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file=\"model.png\",\n",
    "    show_shapes=True,\n",
    "    show_dtype=False,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=True,\n",
    "    dpi=96,\n",
    "    layer_range=None,\n",
    "    show_layer_activations=True,\n",
    ")\n",
    "\n",
    "#visualizer(model, format='png', view=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-23 16:03:34.321553: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 673288560 exceeds 10% of free system memory.\n",
      "2022-02-23 16:03:34.999109: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 128111851 exceeds 10% of free system memory.\n",
      "2022-02-23 16:03:45.107026: W tensorflow/core/common_runtime/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 122.18MiB (rounded to 128111872)requested by op SameWorkerRecvDone\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2022-02-23 16:03:45.107071: I tensorflow/core/common_runtime/bfc_allocator.cc:1027] BFCAllocator dump for GPU_0_bfc\n",
      "2022-02-23 16:03:45.107084: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (256): \tTotal Chunks: 31, Chunks in use: 31. 7.8KiB allocated for chunks. 7.8KiB in use in bin. 136B client-requested in use in bin.\n",
      "2022-02-23 16:03:45.107093: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (512): \tTotal Chunks: 4, Chunks in use: 3. 3.0KiB allocated for chunks. 2.2KiB in use in bin. 1.6KiB client-requested in use in bin.\n",
      "2022-02-23 16:03:45.107100: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (1024): \tTotal Chunks: 4, Chunks in use: 2. 5.0KiB allocated for chunks. 2.5KiB in use in bin. 2.1KiB client-requested in use in bin.\n",
      "2022-02-23 16:03:45.107108: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-02-23 16:03:45.107115: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-02-23 16:03:45.107122: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-02-23 16:03:45.107129: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-02-23 16:03:45.107135: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-02-23 16:03:45.107145: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (65536): \tTotal Chunks: 4, Chunks in use: 3. 338.8KiB allocated for chunks. 266.8KiB in use in bin. 243.0KiB client-requested in use in bin.\n",
      "2022-02-23 16:03:45.107152: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-02-23 16:03:45.107158: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-02-23 16:03:45.107166: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (524288): \tTotal Chunks: 1, Chunks in use: 0. 579.8KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-02-23 16:03:45.107173: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-02-23 16:03:45.107179: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-02-23 16:03:45.107186: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-02-23 16:03:45.107192: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-02-23 16:03:45.107201: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-02-23 16:03:45.107208: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-02-23 16:03:45.107215: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-02-23 16:03:45.107221: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-02-23 16:03:45.107230: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (268435456): \tTotal Chunks: 1, Chunks in use: 1. 735.84MiB allocated for chunks. 735.84MiB in use in bin. 642.10MiB client-requested in use in bin.\n",
      "2022-02-23 16:03:45.107238: I tensorflow/core/common_runtime/bfc_allocator.cc:1050] Bin for 122.18MiB was 64.00MiB, Chunk State: \n",
      "2022-02-23 16:03:45.107244: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] Next region of size 772538368\n",
      "2022-02-23 16:03:45.107255: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7de8000000 of size 1280 next 1\n",
      "2022-02-23 16:03:45.107262: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7de8000500 of size 256 next 2\n",
      "2022-02-23 16:03:45.107268: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7de8000600 of size 256 next 3\n",
      "2022-02-23 16:03:45.107273: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7de8000700 of size 256 next 4\n",
      "2022-02-23 16:03:45.107279: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7de8000800 of size 256 next 5\n",
      "2022-02-23 16:03:45.107284: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7de8000900 of size 256 next 49\n",
      "2022-02-23 16:03:45.107290: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7de8000a00 of size 256 next 41\n",
      "2022-02-23 16:03:45.107296: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7de8000b00 of size 256 next 6\n",
      "2022-02-23 16:03:45.107301: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7de8000c00 of size 256 next 9\n",
      "2022-02-23 16:03:45.107307: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7de8000d00 of size 256 next 10\n",
      "2022-02-23 16:03:45.107313: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7de8000e00 of size 256 next 48\n",
      "2022-02-23 16:03:45.107318: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7de8000f00 of size 256 next 43\n",
      "2022-02-23 16:03:45.107324: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7de8001000 of size 256 next 11\n",
      "2022-02-23 16:03:45.107329: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7de8001100 of size 256 next 12\n",
      "2022-02-23 16:03:45.107335: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7de8001200 of size 256 next 14\n",
      "2022-02-23 16:03:45.107341: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7de8001300 of size 256 next 7\n",
      "2022-02-23 16:03:45.107346: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f7de8001400 of size 768 next 16\n",
      "2022-02-23 16:03:45.107352: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7de8001700 of size 256 next 20\n",
      "2022-02-23 16:03:45.107358: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7de8001800 of size 256 next 21\n",
      "2022-02-23 16:03:45.107363: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7de8001900 of size 256 next 22\n",
      "2022-02-23 16:03:45.107369: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7de8001a00 of size 256 next 23\n",
      "2022-02-23 16:03:45.107375: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7de8001b00 of size 256 next 24\n",
      "2022-02-23 16:03:45.107381: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7de8001c00 of size 256 next 25\n",
      "2022-02-23 16:03:45.107387: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7de8001d00 of size 256 next 17\n",
      "2022-02-23 16:03:45.107392: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f7de8001e00 of size 1280 next 18\n",
      "2022-02-23 16:03:45.107398: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7de8002300 of size 256 next 26\n",
      "2022-02-23 16:03:45.107404: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7de8002400 of size 256 next 27\n",
      "2022-02-23 16:03:45.107409: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7de8002500 of size 256 next 28\n",
      "2022-02-23 16:03:45.107415: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7de8002600 of size 256 next 29\n",
      "2022-02-23 16:03:45.107420: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f7de8002700 of size 593664 next 36\n",
      "2022-02-23 16:03:45.107427: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7de8093600 of size 768 next 37\n",
      "2022-02-23 16:03:45.107433: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7de8093900 of size 98816 next 38\n",
      "2022-02-23 16:03:45.107439: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7de80abb00 of size 1280 next 39\n",
      "2022-02-23 16:03:45.107444: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7de80ac000 of size 768 next 40\n",
      "2022-02-23 16:03:45.107450: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7de80ac300 of size 75520 next 42\n",
      "2022-02-23 16:03:45.107456: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f7de80bea00 of size 1280 next 50\n",
      "2022-02-23 16:03:45.107462: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7de80bef00 of size 256 next 51\n",
      "2022-02-23 16:03:45.107467: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7de80bf000 of size 256 next 52\n",
      "2022-02-23 16:03:45.107473: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7de80bf100 of size 256 next 53\n",
      "2022-02-23 16:03:45.107478: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7de80bf200 of size 256 next 54\n",
      "2022-02-23 16:03:45.107484: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f7de80bf300 of size 73728 next 44\n",
      "2022-02-23 16:03:45.107490: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7de80d1300 of size 256 next 45\n",
      "2022-02-23 16:03:45.107495: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7de80d1400 of size 768 next 46\n",
      "2022-02-23 16:03:45.107501: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7de80d1700 of size 98816 next 47\n",
      "2022-02-23 16:03:45.107507: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f7de80e9900 of size 771581696 next 18446744073709551615\n",
      "2022-02-23 16:03:45.107513: I tensorflow/core/common_runtime/bfc_allocator.cc:1088]      Summary of in-use Chunks by size: \n",
      "2022-02-23 16:03:45.107521: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 31 Chunks of size 256 totalling 7.8KiB\n",
      "2022-02-23 16:03:45.107527: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 3 Chunks of size 768 totalling 2.2KiB\n",
      "2022-02-23 16:03:45.107534: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 2 Chunks of size 1280 totalling 2.5KiB\n",
      "2022-02-23 16:03:45.107541: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 75520 totalling 73.8KiB\n",
      "2022-02-23 16:03:45.107547: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 2 Chunks of size 98816 totalling 193.0KiB\n",
      "2022-02-23 16:03:45.107554: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 771581696 totalling 735.84MiB\n",
      "2022-02-23 16:03:45.107561: I tensorflow/core/common_runtime/bfc_allocator.cc:1095] Sum Total of in-use chunks: 736.11MiB\n",
      "2022-02-23 16:03:45.107568: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] total_region_allocated_bytes_: 772538368 memory_limit_: 772538368 available bytes: 0 curr_region_allocation_bytes_: 1545076736\n",
      "2022-02-23 16:03:45.107867: I tensorflow/core/common_runtime/bfc_allocator.cc:1103] Stats: \n",
      "Limit:                       772538368\n",
      "InUse:                       771867648\n",
      "MaxInUse:                    771867648\n",
      "NumAllocs:                         107\n",
      "MaxAllocSize:                771581696\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2022-02-23 16:03:45.107890: W tensorflow/core/common_runtime/bfc_allocator.cc:491] ****************************************************************************************xxxxxxxxxxxx\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:GPU:0}} SameWorkerRecvDone unable to allocate output tensor. Key: /job:localhost/replica:0/task:0/device:CPU:0;5ded638e35511b02;/job:localhost/replica:0/task:0/device:GPU:0;edge_2_input;0:0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputLines\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:GPU:0}} SameWorkerRecvDone unable to allocate output tensor. Key: /job:localhost/replica:0/task:0/device:CPU:0;5ded638e35511b02;/job:localhost/replica:0/task:0/device:GPU:0;edge_2_input;0:0"
     ]
    }
   ],
   "source": [
    "model.fit(inputLines, target_data, epochs=1-0x7fff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True, False, False, False, False,  True, False,\n",
       "       False,  True,  True, False,  True,  True,  True,  True, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "        True,  True,  True, False,  True, False, False, False,  True,\n",
       "       False,  True,  True, False, False,  True,  True,  True, False,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True,  True, False,  True, False, False,  True,  True, False,\n",
       "       False, False, False, False,  True,  True, False,  True,  True,\n",
       "        True,  True])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_data['binaryData'][50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[9.994783e-01, 9.570409e-04]], dtype=float32), array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
      "        1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0.]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(np.array([inputLines[50]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
